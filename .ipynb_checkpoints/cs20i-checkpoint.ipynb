{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "x = tf.add(a, b)\n",
    "\n",
    "z1=tf.Variable(2)\n",
    "z2=tf.Variable(z1*3)\n",
    "\n",
    "init = tf. global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)                 #variable should be initialized before run\n",
    "    writer = tf.summary.FileWriter('./graphs', sess.graph)\n",
    "    print(sess.run(x))\n",
    "    print(sess.run(z2))\n",
    "\n",
    "# close the writer when you’re done using it\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.874925\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1\n",
    "# Create two 0-d tensors x and y randomly selected from the range [-1, 1). \n",
    "# Return x + y if x < y, x - y if x > y, 0 otherwise. \n",
    " \n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.random_uniform([],-1,1,tf.float32)  \n",
    "y = tf.random_uniform([],-1,1,tf.float32)  \n",
    "\n",
    "out = tf.cond(tf.greater(x, y), lambda: tf.add(x, y), lambda: tf.subtract(x, y))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('./graphs', sess.graph)\n",
    "    print(sess.run(out1))\n",
    "\n",
    "# close the writer when you’re done using it\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out_matrix= [[ True False False]\n",
      " [ True False False]] \n",
      " out= b'x<>y'\n"
     ]
    }
   ],
   "source": [
    "# 1c: Create the tensor x of the value [[0, -2, -1], [0, 1, 2]]  \n",
    "# and y as a tensor of zeros with the same shape as x. \n",
    "# Return a boolean tensor that yields Trues if x equals y element-wise. \n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([[0,-2,-1],[0,1,2]])  \n",
    "y = tf.zeros_like(x)\n",
    "\n",
    "out_matrix = tf.equal(x,y)\n",
    "out = tf.cond(tf.reduce_all(out_matrix), lambda: tf.constant(\"x==y\"), lambda: tf.constant(\"x<>y\"))\n",
    "#use tf.reduce_all() to calculate the \"AND\" of out_matrix \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('./graphs', sess.graph)\n",
    "    sess.run(out)\n",
    "    print(\"out_matrix=\",out_matrix.eval(),\"\\n out=\",out.eval())\n",
    "\n",
    "# close the writer when you’re done using it\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index= [[ 2]\n",
      " [ 4]\n",
      " [ 6]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [11]\n",
      " [14]\n",
      " [16]\n",
      " [18]] \n",
      " elements= [[ 31.19073486]\n",
      " [ 30.97266006]\n",
      " [ 38.08450317]\n",
      " [ 34.94445419]\n",
      " [ 34.45999146]\n",
      " [ 36.01657104]\n",
      " [ 30.20379066]\n",
      " [ 33.71149445]\n",
      " [ 36.05556488]]\n"
     ]
    }
   ],
   "source": [
    "# 1d: Create the tensor x of value  \n",
    "# [29.05088806,  27.61298943,  31.19073486,  29.35532951, \n",
    "#  30.97266006,  26.67541885,  38.08450317,  20.74983215, \n",
    "#  34.94445419,  34.45999146,  29.06485367,  36.01657104, \n",
    "#  27.88236427,  20.56035233,  30.20379066,  29.51215172, \n",
    "#  33.71149445,  28.59134293,  36.05556488,  28.66994858]. \n",
    "# Get the indices of elements in x whose values are greater than 30. \n",
    "# Hint: Use tf.where(). \n",
    "# Then extract elements whose values are greater than 30. \n",
    "# Hint: Use tf.gather(). \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.constant([29.05088806,  27.61298943,  31.19073486,  29.35532951, 30.97266006,  26.67541885,  38.08450317,  \n",
    "                 20.74983215,  34.94445419,  34.45999146,  29.06485367, 36.01657104,  27.88236427,  20.56035233,  \n",
    "                 30.20379066,  29.51215172,  33.71149445,  28.59134293,  36.05556488,  28.66994858])  \n",
    "\n",
    "index1 = tf.where(tf.greater(x,30))\n",
    "y = tf.gather(x,index1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter('./graphs', sess.graph)\n",
    "    sess.run(y)\n",
    "    print(\"index=\",index1.eval(), \"\\n elements=\",y.eval())   #use eval() to get tensors' values\n",
    "\n",
    "# close the writer when you’re done using it\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= [[-0.78379864 -0.8799755   0.37604228  1.63633704 -0.82838857 -0.04455893\n",
      "   0.15963933  0.62386501 -1.60040128 -0.87235808]\n",
      " [ 0.07639593 -0.31932828 -0.72479635  0.18012115  1.8619473  -0.146313\n",
      "   0.03198522  1.07446122  0.86385459  1.00829923]\n",
      " [-1.12227273 -1.46497047  1.46730709 -1.48122108  0.04535477  0.0066001\n",
      "   0.87414569 -1.9206351  -0.43671948 -1.21504879]\n",
      " [-1.15419638  0.65740174  0.05460649  0.06995057 -0.394903   -0.82839906\n",
      "   0.60587996  1.53653324  1.1973865  -1.01755452]\n",
      " [ 0.57505763 -0.80980355 -0.96888632  1.46756852  0.7574262   1.71182954\n",
      "   0.54248905 -0.21837139  1.09567666 -0.03912353]\n",
      " [ 1.39948773 -0.13692939 -1.47015607  0.31468093 -0.8919661   1.1780231\n",
      "   0.31445968  0.51901144  0.58536905 -0.08157604]\n",
      " [ 1.23231721 -0.77553743  0.66753858  1.75020432 -1.65545022 -0.41431254\n",
      "  -0.78990555 -0.09853531  1.16550648 -0.85461271]\n",
      " [-0.32113415  0.2015916   0.76873451  0.61456573  1.67802203  0.97909021\n",
      "   0.14664561 -0.45679244 -0.19916455 -1.1910162 ]\n",
      " [-1.40345216 -0.4171024  -0.09391126 -0.7102747   0.38859913  0.45236817\n",
      "  -1.52915907 -1.64741492  0.2161231  -0.15200725]\n",
      " [-0.17454551 -0.93172157  0.88866359 -0.25187439  0.89140165  1.18076003\n",
      "   1.29211962  1.14029777  1.39098179  1.41101253]] \n",
      " tf.determinant(x)= 203.647\n"
     ]
    }
   ],
   "source": [
    "# 1f: Create a random 2-d tensor of size 10 x 10 from any distribution. \n",
    "# Calculate its determinant. \n",
    "# Hint: Look at tf.matrix_determinant(). \n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "x=tf.truncated_normal(shape=[10,10], mean=0, stddev=1)\n",
    "y=tf.matrix_determinant(x)\n",
    "\n",
    "init = tf. global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(y)\n",
    "    print(\"x=\",x.eval(),\"\\n tf.determinant(x)=\",y.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data= [[   6.2   29. ]\n",
      " [   9.5   44. ]\n",
      " [  10.5   36. ]\n",
      " [   7.7   37. ]\n",
      " [   8.6   53. ]\n",
      " [  34.1   68. ]\n",
      " [  11.    75. ]\n",
      " [   6.9   18. ]\n",
      " [   7.3   31. ]\n",
      " [  15.1   25. ]\n",
      " [  29.1   34. ]\n",
      " [   2.2   14. ]\n",
      " [   5.7   11. ]\n",
      " [   2.    11. ]\n",
      " [   2.5   22. ]\n",
      " [   4.    16. ]\n",
      " [   5.4   27. ]\n",
      " [   2.2    9. ]\n",
      " [   7.2   29. ]\n",
      " [  15.1   30. ]\n",
      " [  16.5   40. ]\n",
      " [  18.4   32. ]\n",
      " [  36.2   41. ]\n",
      " [  39.7  147. ]\n",
      " [  18.5   22. ]\n",
      " [  23.3   29. ]\n",
      " [  12.2   46. ]\n",
      " [   5.6   23. ]\n",
      " [  21.8    4. ]\n",
      " [  21.6   31. ]\n",
      " [   9.    39. ]\n",
      " [   3.6   15. ]\n",
      " [   5.    32. ]\n",
      " [  28.6   27. ]\n",
      " [  17.4   32. ]\n",
      " [  11.3   34. ]\n",
      " [   3.4   17. ]\n",
      " [  11.9   46. ]\n",
      " [  10.5   42. ]\n",
      " [  10.7   43. ]\n",
      " [  10.8   34. ]\n",
      " [   4.8   19. ]]\n",
      "Epoch 0: 2069.6319333978354\n",
      "Epoch 1: 2117.0123581953535\n",
      "Epoch 2: 2092.302723001866\n",
      "Epoch 3: 2068.5080461938464\n",
      "Epoch 4: 2045.591184088162\n",
      "Epoch 5: 2023.5146448101316\n",
      "Epoch 6: 2002.2447619835536\n",
      "Epoch 7: 1981.748338803649\n",
      "Epoch 8: 1961.9944411260742\n",
      "Epoch 9: 1942.9520116143283\n",
      "Epoch 10: 1924.5930823644712\n",
      "Epoch 11: 1906.8898800636332\n",
      "Epoch 12: 1889.8164505837929\n",
      "Epoch 13: 1873.347133841543\n",
      "Epoch 14: 1857.4588400604468\n",
      "Epoch 15: 1842.1278742424079\n",
      "Epoch 16: 1827.332495119955\n",
      "Epoch 17: 1813.0520579712022\n",
      "Epoch 18: 1799.2660847636982\n",
      "Epoch 19: 1785.9562132299961\n",
      "Epoch 20: 1773.1024853109072\n",
      "Epoch 21: 1760.689129482884\n",
      "Epoch 22: 1748.6984157081515\n",
      "Epoch 23: 1737.1138680398553\n",
      "Epoch 24: 1725.920873066732\n",
      "Epoch 25: 1715.1046249579008\n",
      "Epoch 26: 1704.6500954309377\n",
      "Epoch 27: 1694.5447134910141\n",
      "Epoch 28: 1684.7746311347667\n",
      "Epoch 29: 1675.328450968245\n",
      "Epoch 30: 1666.1935385839038\n",
      "Epoch 31: 1657.3584002084322\n",
      "Epoch 32: 1648.8122658529207\n",
      "Epoch 33: 1640.5440742547091\n",
      "Epoch 34: 1632.5446836102221\n",
      "Epoch 35: 1624.8043315147183\n",
      "Epoch 36: 1617.3126799958602\n",
      "Epoch 37: 1610.0622532456405\n",
      "Epoch 38: 1603.0433557207386\n",
      "Epoch 39: 1596.2479176106197\n",
      "Epoch 40: 1589.668056331575\n",
      "Epoch 41: 1583.2965242617897\n",
      "Epoch 42: 1577.126371285745\n",
      "Epoch 43: 1571.1501190634\n",
      "Epoch 44: 1565.360979151513\n",
      "Epoch 45: 1559.7523780798629\n",
      "Epoch 46: 1554.3184364555138\n",
      "Epoch 47: 1549.0529469620615\n",
      "Epoch 48: 1543.950059985476\n",
      "Epoch 49: 1539.0050282141283\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc477c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import xlrd\n",
    "\n",
    "DATA_FILE = 'data/fire_theft.xls'\n",
    "\n",
    "# Step 1: read in data from the .xls file\n",
    "book = xlrd.open_workbook(DATA_FILE, encoding_override=\"utf-8\")\n",
    "sheet = book.sheet_by_index(0)\n",
    "data = np.asarray([sheet.row_values(i) for i in range(1, sheet.nrows)])\n",
    "print(\"data=\",data)\n",
    "n_samples = sheet.nrows - 1\n",
    "\n",
    "# Step 2: create placeholders for input X (number of fire) and label Y (number of theft)\n",
    "X = tf.placeholder(tf.float32, name='X')\n",
    "Y = tf.placeholder(tf.float32, name='Y')\n",
    "\n",
    "# Step 3: create weight and bias, initialized to 0\n",
    "w = tf.Variable(0.0, name='weights')\n",
    "b = tf.Variable(0.0, name='bias')\n",
    "\n",
    "# Step 4: build model to predict Y\n",
    "Y_predicted = X * w + b \n",
    "\n",
    "# Step 5: use the square error as the loss function\n",
    "loss = tf.square(Y - Y_predicted, name='loss')\n",
    "# loss = utils.huber_loss(Y, Y_predicted)\n",
    "\n",
    "# Step 6: using gradient descent with learning rate of 0.01 to minimize loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Step 7: initialize the necessary variables, in this case, w and b\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    writer = tf.summary.FileWriter('./graphs/linear_reg', sess.graph)\n",
    "\n",
    "    # Step 8: train the model\n",
    "    for i in range(50): # train the model 50 epochs\n",
    "        total_loss = 0\n",
    "        for x, y in data:\n",
    "            # Session runs train_op and fetch values of loss\n",
    "            _, lo= sess.run([optimizer, loss], feed_dict={X: x, Y:y}) \n",
    "            total_loss += lo                      #Accumulate loss into total_loss\n",
    "        print('Epoch {0}: {1}'.format(i, total_loss/n_samples))  #total_loss/n_samples = mean of loss of every epoch\n",
    "\n",
    "    # close the writer when you're done using it\n",
    "    writer.close() \n",
    "\n",
    "    # Step 9: output the values of w and b\n",
    "    w, b = sess.run([w, b]) \n",
    "\n",
    "# plot the results\n",
    "X, Y = data.T[0], data.T[1]\n",
    "plt.plot(X, Y, 'bo', label='Real data')\n",
    "plt.plot(X, X * w + b, 'r', label='Predicted data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
